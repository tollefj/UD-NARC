{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From manual checks:\n",
    "NARC v1.0:\n",
    "\n",
    "- 357 bokmÃ¥l files\n",
    "- 401 nynorsk files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__T204', '__T203']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = '(vg~vg_20111003_10039641__2401--1-(vg~vg_20111003_10039641__81112--1-)'\n",
    "e2 = 'vg~vg_20111003_10039641__T204)vg~vg_20111003_10039641__T203)'\n",
    "\n",
    "import re\n",
    "def parse_ent_str(estr):\n",
    "    cluster_pattern = re.compile(r'__\\d+')\n",
    "    markable_pattern = re.compile(r'__T\\d+')\n",
    "    return cluster_pattern.findall(estr) + markable_pattern.findall(estr)\n",
    "\n",
    "parse_ent_str(e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_lang_stats(path):\n",
    "    # path = f\"narc-merged/annotations_conll_{lang}\"\n",
    "    total_sents = 0\n",
    "    total_toks = 0\n",
    "    total_references = 0\n",
    "    entities = []\n",
    "    # keep track of all entities along with their count (occurrence)\n",
    "    entity_counts = defaultdict(int)\n",
    "\n",
    "    norne_entities = []\n",
    "    for doc_count, conll in enumerate(os.listdir(path)):\n",
    "        if not conll.endswith(\".conllu\"):\n",
    "            continue\n",
    "        parsed = parse(open(os.path.join(path, conll), encoding=\"utf-8\").read())\n",
    "        for sentence in parsed:\n",
    "            total_sents += 1\n",
    "            for token in sentence:\n",
    "                total_toks += 1\n",
    "                if token[\"misc\"] is not None:\n",
    "                    if \"Entity\" in token[\"misc\"]:\n",
    "                        # count entities by counting \"__\" as each entity\n",
    "                        actual_ents = token[\"misc\"][\"Entity\"]\n",
    "                        parsed = list(parse_ent_str(actual_ents))\n",
    "                        for ent in parsed:\n",
    "                            entity_counts[f\"{ent}_{doc_count}\"] += 1\n",
    "\n",
    "                        entities.extend(parsed)\n",
    "                    if \"name\" in token[\"misc\"]:\n",
    "                        # filter out all names that are not \"O\"\n",
    "                        named_ents = token[\"misc\"][\"name\"]\n",
    "                        named_ents = [n for n in named_ents if n != \"O\"]\n",
    "                        norne_entities.extend(named_ents)\n",
    "        \n",
    "    references = len(entities)\n",
    "    unique_ents = set(entities)\n",
    "\n",
    "    norne_unique = set(norne_entities)\n",
    "\n",
    "    # find singletons: entities that only occur once\n",
    "    _singletons = [k for k, v in entity_counts.items() if v == 1]\n",
    "    _corefs = [k for k, v in entity_counts.items() if v > 1]\n",
    "    \n",
    "\n",
    "    print(f\"\"\"\n",
    "    {path}\n",
    "    {total_sents} sentences, \n",
    "    {total_toks} tokens, \n",
    "    {total_toks/total_sents} tokens/sent, \n",
    "    {references} references, \n",
    "    {len(_singletons)} singletons,\n",
    "    {len(_corefs)} coreferences,\n",
    "    {len(_singletons) + len(_corefs)} total entities (coref+singleton),\n",
    "    {len(norne_entities)} norne entities,\n",
    "    {len(norne_unique)} unique norne entities,\n",
    "    {len(unique_ents)} unique entities\n",
    "    \"\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NARC Original results (v1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ../output/narc/annotations_conll_bokmaal\n",
      "    16461 sentences, \n",
      "    257646 tokens, \n",
      "    15.651904501549117 tokens/sent, \n",
      "    116288 references, \n",
      "    18327 singletons,\n",
      "    36898 coreferences,\n",
      "    55225 total entities (coref+singleton),\n",
      "    0 norne entities,\n",
      "    0 unique norne entities,\n",
      "    5073 unique entities\n",
      "    \n",
      "\n",
      "    ../output/narc/annotations_conll_nynorsk\n",
      "    12762 sentences, \n",
      "    213222 tokens, \n",
      "    16.707569346497415 tokens/sent, \n",
      "    95671 references, \n",
      "    15228 singletons,\n",
      "    30690 coreferences,\n",
      "    45918 total entities (coref+singleton),\n",
      "    0 norne entities,\n",
      "    0 unique norne entities,\n",
      "    3529 unique entities\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lang in [\"bokmaal\", \"nynorsk\"]:\n",
    "    path = f\"../output/narc/annotations_conll_{lang}\"\n",
    "    # path = f\"../../output/narc/{lang}\"\n",
    "    # path = f\"narc-merged/OUTPUT/no-narc_{lang}\"\n",
    "    get_lang_stats(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NARC aligned results (information loss!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ../output/aligned/no-narc_bokmaal\n",
      "    15672 sentences, \n",
      "    244136 tokens, \n",
      "    15.57784583971414 tokens/sent, \n",
      "    111091 references, \n",
      "    278 singletons,\n",
      "    6214 coreferences,\n",
      "    6492 total entities (coref+singleton),\n",
      "    84410 norne entities,\n",
      "    15 unique norne entities,\n",
      "    4934 unique entities\n",
      "    \n",
      "\n",
      "    ../output/aligned/no-narc_nynorsk\n",
      "    12481 sentences, \n",
      "    206660 tokens, \n",
      "    16.557968111529526 tokens/sent, \n",
      "    93346 references, \n",
      "    60 singletons,\n",
      "    4859 coreferences,\n",
      "    4919 total entities (coref+singleton),\n",
      "    80243 norne entities,\n",
      "    15 unique norne entities,\n",
      "    3472 unique entities\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lang in [\"bokmaal\", \"nynorsk\"]:\n",
    "    path = f\"../output/aligned/no-narc_{lang}\"\n",
    "    get_lang_stats(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ../data/UD/UD_Norwegian-Bokmaal\n",
      "    20044 sentences, \n",
      "    310221 tokens, \n",
      "    15.477000598682897 tokens/sent, \n",
      "    0 references, \n",
      "    0 singletons,\n",
      "    0 coreferences,\n",
      "    0 total entities (coref+singleton),\n",
      "    0 norne entities,\n",
      "    0 unique norne entities,\n",
      "    0 unique entities\n",
      "    \n",
      "\n",
      "    ../data/UD/UD_Norwegian-Nynorsk\n",
      "    17575 sentences, \n",
      "    301353 tokens, \n",
      "    17.14668563300142 tokens/sent, \n",
      "    0 references, \n",
      "    0 singletons,\n",
      "    0 coreferences,\n",
      "    0 total entities (coref+singleton),\n",
      "    0 norne entities,\n",
      "    0 unique norne entities,\n",
      "    0 unique entities\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lang in [\"bokmaal\", \"nynorsk\"]:\n",
    "    _ud = f\"UD_Norwegian-{lang.capitalize()}\"\n",
    "    ud_path = f\"../data/UD/{_ud}\"\n",
    "    get_lang_stats(ud_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NorNE stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ../data/norne/ud/nob\n",
      "    20045 sentences, \n",
      "    310222 tokens, \n",
      "    15.476278373659266 tokens/sent, \n",
      "    0 references, \n",
      "    0 singletons,\n",
      "    0 coreferences,\n",
      "    0 total entities (coref+singleton),\n",
      "    105162 norne entities,\n",
      "    15 unique norne entities,\n",
      "    0 unique entities\n",
      "    \n",
      "\n",
      "    ../data/norne/ud/nno\n",
      "    17575 sentences, \n",
      "    301353 tokens, \n",
      "    17.14668563300142 tokens/sent, \n",
      "    0 references, \n",
      "    0 singletons,\n",
      "    0 coreferences,\n",
      "    0 total entities (coref+singleton),\n",
      "    103829 norne entities,\n",
      "    15 unique norne entities,\n",
      "    0 unique entities\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lang in [\"bokmaal\", \"nynorsk\"]:\n",
    "    _id = \"nno\" if lang == \"nynorsk\" else \"nob\"\n",
    "    path = f\"../data/norne/ud/{_id}\"\n",
    "    get_lang_stats(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29f1e52c0d8d5e5ede6aaca4be8238d35b46afd62a3b8286547e2768de775769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
