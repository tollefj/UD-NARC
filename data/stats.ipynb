{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From manual checks:\n",
    "NARC v0.6:\n",
    "\n",
    "- 357 bokmÃ¥l files\n",
    "- 401 nynorsk files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__T204', '__T203']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = '(vg~vg_20111003_10039641__2401--1-(vg~vg_20111003_10039641__81112--1-)'\n",
    "e2 = 'vg~vg_20111003_10039641__T204)vg~vg_20111003_10039641__T203)'\n",
    "\n",
    "import re\n",
    "def parse_ent_str(estr):\n",
    "    cluster_pattern = re.compile(r'__\\d+')\n",
    "    markable_pattern = re.compile(r'__T\\d+')\n",
    "    return cluster_pattern.findall(estr) + markable_pattern.findall(estr)\n",
    "\n",
    "parse_ent_str(e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang_stats(path):\n",
    "    # path = f\"narc-merged/annotations_conll_{lang}\"\n",
    "    total_sents = 0\n",
    "    total_toks = 0\n",
    "    total_references = 0\n",
    "    entities = []\n",
    "    norne_entities = []\n",
    "    for conll in os.listdir(path):\n",
    "        if not conll.endswith(\".conllu\"):\n",
    "            continue\n",
    "        parsed = parse(open(os.path.join(path, conll)).read())\n",
    "        for sentence in parsed:\n",
    "            total_sents += 1\n",
    "            for token in sentence:\n",
    "                total_toks += 1\n",
    "                if token[\"misc\"] is not None:\n",
    "                    if \"Entity\" in token[\"misc\"]:\n",
    "                        # count entities by counting \"__\" as each entity\n",
    "                        actual_ents = token[\"misc\"][\"Entity\"]\n",
    "                        parsed = parse_ent_str(actual_ents)\n",
    "                        entities.extend(parsed)\n",
    "                    if \"name\" in token[\"misc\"]:\n",
    "                        # filter out all names that are not \"O\"\n",
    "                        named_ents = token[\"misc\"][\"name\"]\n",
    "                        named_ents = [n for n in named_ents if n != \"O\"]\n",
    "                        norne_entities.extend(named_ents)\n",
    "        \n",
    "    references = len(entities)\n",
    "    unique_ents = set(entities)\n",
    "\n",
    "    norne_unique = set(norne_entities)\n",
    "\n",
    "    print(f\"\"\"\n",
    "    {path}\n",
    "    {total_sents} sentences, \n",
    "    {total_toks} tokens, \n",
    "    {total_toks/total_sents} tokens/sent, \n",
    "    {references} references, \n",
    "    {len(norne_entities)} norne entities,\n",
    "    {len(norne_unique)} unique norne entities,\n",
    "    {len(unique_ents)} unique entities\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    bokmaal: \n",
      "    15742 sentences, \n",
      "    245515 tokens, \n",
      "    15.596175835344937 tokens/sent, \n",
      "    111663 references, \n",
      "    84826 norne entities,\n",
      "    15 unique norne entities,\n",
      "    4961 unique entities\n",
      "    \n",
      "\n",
      "    nynorsk: \n",
      "    12481 sentences, \n",
      "    206660 tokens, \n",
      "    16.557968111529526 tokens/sent, \n",
      "    93346 references, \n",
      "    80243 norne entities,\n",
      "    15 unique norne entities,\n",
      "    3472 unique entities\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lang in [\"bokmaal\", \"nynorsk\"]:\n",
    "    path = f\"narc-merged/OUTPUT/no-narc_{lang}\"\n",
    "    get_lang_stats(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    bokmaal: \n",
      "    16531 sentences, \n",
      "    259026 tokens, \n",
      "    15.669106527130845 tokens/sent, \n",
      "    116861 references, \n",
      "    0 norne entities,\n",
      "    0 unique norne entities,\n",
      "    5098 unique entities\n",
      "    \n",
      "\n",
      "    nynorsk: \n",
      "    12762 sentences, \n",
      "    213222 tokens, \n",
      "    16.707569346497415 tokens/sent, \n",
      "    95671 references, \n",
      "    0 norne entities,\n",
      "    0 unique norne entities,\n",
      "    3529 unique entities\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lang in [\"bokmaal\", \"nynorsk\"]:\n",
    "    path = f\"narc-merged/annotations_conll_{lang}\"\n",
    "    get_lang_stats(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ../UD/UD_Norwegian-Bokmaal\n",
      "    20044 sentences, \n",
      "    310221 tokens, \n",
      "    15.477000598682897 tokens/sent, \n",
      "    0 references, \n",
      "    0 norne entities,\n",
      "    0 unique norne entities,\n",
      "    0 unique entities\n",
      "    \n",
      "\n",
      "    ../UD/UD_Norwegian-Nynorsk\n",
      "    17575 sentences, \n",
      "    301353 tokens, \n",
      "    17.14668563300142 tokens/sent, \n",
      "    0 references, \n",
      "    0 norne entities,\n",
      "    0 unique norne entities,\n",
      "    0 unique entities\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lang in [\"bokmaal\", \"nynorsk\"]:\n",
    "    _ud = f\"UD_Norwegian-{lang.capitalize()}\"\n",
    "    ud_path = f\"../UD/{_ud}\"\n",
    "    get_lang_stats(ud_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ../NorNE/ud/nob\n",
      "    20045 sentences, \n",
      "    310222 tokens, \n",
      "    15.476278373659266 tokens/sent, \n",
      "    0 references, \n",
      "    105162 norne entities,\n",
      "    15 unique norne entities,\n",
      "    0 unique entities\n",
      "    \n",
      "\n",
      "    ../NorNE/ud/nno\n",
      "    17575 sentences, \n",
      "    301353 tokens, \n",
      "    17.14668563300142 tokens/sent, \n",
      "    0 references, \n",
      "    103829 norne entities,\n",
      "    15 unique norne entities,\n",
      "    0 unique entities\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for lang in [\"bokmaal\", \"nynorsk\"]:\n",
    "    _id = \"nno\" if lang == \"nynorsk\" else \"nob\"\n",
    "    path = f\"../NorNE/ud/{_id}\"\n",
    "    get_lang_stats(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0775435930626296"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stat_loss_from_original(orig: int, new: int) -> float:\n",
    "    val = (orig - new) / orig\n",
    "    # as perc:\n",
    "    return val * 100\n",
    "\n",
    "stat_loss_from_original(16531, 15742) #bm sent\n",
    "stat_loss_from_original(259026, 245515) #bm tok\n",
    "\n",
    "stat_loss_from_original(12762, 12481) #nn sent\n",
    "stat_loss_from_original(213222, 206660) #nn tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1070\n"
     ]
    }
   ],
   "source": [
    "before_sents = 16531 + 12762\n",
    "after_sents = 15742 + 12481\n",
    "loss = before_sents - after_sents\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20073\n"
     ]
    }
   ],
   "source": [
    "before = 259026 + 213222\n",
    "after = 245515 + 206660\n",
    "loss = before - after\n",
    "print(loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29f1e52c0d8d5e5ede6aaca4be8238d35b46afd62a3b8286547e2768de775769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
